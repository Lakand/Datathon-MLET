# API Passos MÃ¡gicos - PrevisÃ£o de Risco de Defasagem Escolar

## ğŸ“‹ VisÃ£o Geral do Projeto

### Objetivo

Este projeto foi desenvolvido para o programa **Passos MÃ¡gicos**, uma organizaÃ§Ã£o que trabalha com alunos em situaÃ§Ã£o de vulnerabilidade social. O objetivo principal Ã© **prever o risco de defasagem escolar** dos alunos, classificando-os em quatro categorias (representadas por nomes de pedras):

- **Quartzo** - Sem risco aparente
- **Ãgata** - Risco baixo
- **Ametista** - Risco mÃ©dio  
- **TopÃ¡zio** - Risco alto

A defasagem escolar Ã© um indicador crÃ­tico do desempenho acadÃªmico e do engajamento dos alunos no programa, permitindo intervenÃ§Ãµes preventivas direcionadas.

### SoluÃ§Ã£o Proposta

A soluÃ§Ã£o implementa uma **pipeline completa de Machine Learning** em produÃ§Ã£o:

1. **Coleta e Limpeza de Dados**: UnificaÃ§Ã£o de dados de mÃºltiplas safras (2022-2024) com esquemas heterogÃªneos
2. **Engenharia de Features**: TransformaÃ§Ã£o e normalizaÃ§Ã£o automÃ¡tica de variÃ¡veis
3. **Treinamento do Modelo**: Classificador neural (MLPClassifier) com validaÃ§Ã£o cruzada estratificada
4. **Deploy em API**: FastAPI com endpoints RESTful para prediÃ§Ã£o, treinamento e monitoramento
5. **Monitoramento de Drift**: DetecÃ§Ã£o automÃ¡tica de mudanÃ§as na distribuiÃ§Ã£o dos dados em produÃ§Ã£o
6. **Registro de Experimentos**: Rastreamento de modelos e mÃ©tricas com MLflow

### Stack TecnolÃ³gica

| Componente | Tecnologias |
|-----------|------------|
| **API & Deploy** | FastAPI, Uvicorn, Python 3.10 |
| **Machine Learning** | Scikit-Learn, XGBoost, Imbalanced-Learn (SMOTE) |
| **Dados** | Pandas, NumPy, Openpyxl |
| **MLOps** | MLflow (rastreamento de experimentos), Evidently (drift detection) |
| **ContainerizaÃ§Ã£o** | Docker, Docker Compose |
| **Testes** | Pytest, Pytest-Cov |
| **VisualizaÃ§Ã£o** | Matplotlib, Seaborn |

---

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ app/                           # AplicaÃ§Ã£o FastAPI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # Ponto de entrada da API
â”‚   â”œâ”€â”€ routes.py                  # DefiniÃ§Ã£o dos endpoints
â”‚   â”œâ”€â”€ schemas.py                 # Modelos Pydantic (validaÃ§Ã£o)
â”‚   â””â”€â”€ monitor.py                 # Logging e monitoramento
â”‚
â”œâ”€â”€ src/                           # LÃ³gica de ML e processamento
â”‚   â”œâ”€â”€ config.py                  # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ preprocessing.py           # Limpeza e padronizaÃ§Ã£o de dados
â”‚   â”œâ”€â”€ feature_engineering.py     # TransformaÃ§Ã£o de features
â”‚   â”œâ”€â”€ train.py                   # Pipeline de treinamento
â”‚   â”œâ”€â”€ evaluate.py                # AvaliaÃ§Ã£o do modelo
â”‚   â”œâ”€â”€ drift_report.py            # GeraÃ§Ã£o de relatÃ³rios de drift
â”‚   â””â”€â”€ utils.py                   # FunÃ§Ãµes auxiliares
â”‚
â”œâ”€â”€ tests/                         # Suite de testes
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_drift_report.py
â”‚   â”œâ”€â”€ test_feature_engineering.py
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ data/                          # Dados e base de dados
â”‚   â”œâ”€â”€ BASE DE DADOS PEDE 2024 - DATATHON.xlsx
â”‚   â””â”€â”€ test_dataset.csv
â”‚
â”œâ”€â”€ models/                        # Artefatos de ML
â”‚   â”œâ”€â”€ mlp_model.joblib           # Modelo treinado
â”‚   â””â”€â”€ pipeline_features.joblib   # Pipeline de transformaÃ§Ã£o
â”‚
â”œâ”€â”€ docs/                          # DocumentaÃ§Ã£o e relatÃ³rios
â”‚   â””â”€â”€ drift_report.html
â”‚
â”œâ”€â”€ notebooks/                     # AnÃ¡lise exploratÃ³ria
â”‚   â””â”€â”€ exploracao_dados.ipynb
â”‚
â”œâ”€â”€ mlruns/                        # Artefatos e histÃ³rico do MLflow
â”‚
â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â”œâ”€â”€ Dockerfile                     # Imagem Docker da aplicaÃ§Ã£o
â”œâ”€â”€ docker-compose.yml             # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ pytest.ini                     # ConfiguraÃ§Ã£o de testes
â””â”€â”€ README.md                      # Este arquivo
```

---

## ğŸš€ InstruÃ§Ãµes de Deploy

### PrÃ©-requisitos

- **Docker** 20.10+
- **Docker Compose** 1.29+ (recomendado)
- **Python** 3.10+ (para desenvolvimento local)
- **Pip** ou **Conda**

### InstalaÃ§Ã£o de DependÃªncias (Desenvolvimento Local)

#### Via Pip

```bash
# Clonar o repositÃ³rio ou navegar atÃ© a pasta do projeto
cd "Python/Fase 5"

# Criar um ambiente virtual (opcional, mas recomendado)
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

#### Via Conda (Alternativa)

```bash
conda create -n passos-magicos python=3.10
conda activate passos-magicos
pip install -r requirements.txt
```

---

### Deploy com Docker Compose (Recomendado)

Este Ã© o mÃ©todo mais simples para executar a aplicaÃ§Ã£o em produÃ§Ã£o.

#### 1. Build e ExecuÃ§Ã£o

```bash
# Navegar atÃ© a pasta do projeto
cd "Python/Fase 5"

# Build da imagem Docker
docker-compose build

# Iniciar a aplicaÃ§Ã£o
docker-compose up -d

# Verificar logs em tempo real
docker-compose logs -f api-passos-magicos
```

#### 2. Parar a AplicaÃ§Ã£o

```bash
docker-compose down
```

#### 3. Estrutura do Docker Compose

A aplicaÃ§Ã£o serÃ¡ disponibilizada em **http://127.0.0.1:8000** com os seguintes volumes montados:

- `./data:/app/data` - Base de dados e arquivos de entrada
- `./models:/app/models` - Artefatos de ML (modelos treinados)
- `./docs:/app/docs` - RelatÃ³rios gerados
- `./mlruns:/app/mlruns` - HistÃ³rico de experimentos (MLflow)

---

### Deploy com Docker (Alternativa Manual)

#### 1. Build da Imagem

```bash
docker build -t passos-magicos-api:latest .
```

#### 2. ExecuÃ§Ã£o do Container

```bash
docker run -d \
  --name passos-magicos-api \
  -p 8000:8000 \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/docs:/app/docs \
  -v $(pwd)/mlruns:/app/mlruns \
  -e PYTHONUNBUFFERED=1 \
  -e DB_PATH=/app/data/monitoring.db \
  passos-magicos-api:latest
```

#### 3. Acessar a API

- **URL Base**: http://127.0.0.1:8000
- **DocumentaÃ§Ã£o Interativa (Swagger UI)**: http://127.0.0.1:8000/docs
- **DocumentaÃ§Ã£o Alternativa (ReDoc)**: http://127.0.0.1:8000/redoc

---

## ğŸ”Œ Exemplos de Chamadas Ã  API

### 1. PrediÃ§Ã£o de Risco (POST /predict)

Realiza prediÃ§Ã£o de risco de defasagem para um ou mais alunos.

#### Usando cURL

```bash
curl -X POST "http://127.0.0.1:8000/predict" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "RA": "123456",
      "IDADE": 14,
      "GENERO": "Menino",
      "ANO_INGRESSO": 2022,
      "FASE": 1,
      "NOTA_MAT": 8.5,
      "NOTA_PORT": 7.0,
      "NOTA_ING": 6.5,
      "IEG": 7.0,
      "IPS": 6.5,
      "IAA": 8.0,
      "IPP": 7.5,
      "DEFASAGEM": 0
    }
  ]'
```

#### Usando Python + Requests

```python
import requests
import json

url = "http://127.0.0.1:8000/predict"

payload = [
    {
        "RA": "123456",
        "IDADE": 14,
        "GENERO": "Menino",
        "ANO_INGRESSO": 2022,
        "FASE": 1,
        "NOTA_MAT": 8.5,
        "NOTA_PORT": 7.0,
        "NOTA_ING": 6.5,
        "IEG": 7.0,
        "IPS": 6.5,
        "IAA": 8.0,
        "IPP": 7.5,
        "DEFASAGEM": 0
    }
]

response = requests.post(url, json=payload)
print(json.dumps(response.json(), indent=2, ensure_ascii=False))
```

**Resposta Esperada:**

```json
{
  "predictions": [
    {
      "RA": "123456",
      "PEDRA_PREVISTA": "Quartzo",
      "RISCO_DEFASAGEM": "Baixo",
      "CONFIANCA": 0.92
    }
  ]
}
```

#### Usando Postman

1. Abrir Postman
2. Criar uma nova requisiÃ§Ã£o **POST**
3. **URL**: `http://127.0.0.1:8000/predict`
4. **Headers**: `Content-Type: application/json`
5. **Body** (raw, JSON):
```json
[
  {
    "RA": "123456",
    "IDADE": 14,
    "GENERO": "Menino",
    "ANO_INGRESSO": 2022,
    "FASE": 1,
    "NOTA_MAT": 8.5,
    "NOTA_PORT": 7.0,
    "NOTA_ING": 6.5,
    "IEG": 7.0,
    "IPS": 6.5,
    "IAA": 8.0,
    "IPP": 7.5,
    "DEFASAGEM": 0
  }
]
```
6. Clicar **Send**

---

### 2. Treinamento do Modelo (POST /train)

Treina um novo modelo usando todos os dados disponÃ­veis.

#### Usando cURL

```bash
curl -X POST "http://127.0.0.1:8000/train"
```

#### Usando Python

```python
import requests

url = "http://127.0.0.1:8000/train"
response = requests.post(url)
print(response.json())
```

**Resposta Esperada:**

```json
{
  "message": "Treinamento concluÃ­do e modelo atualizado!",
  "details": {
    "accuracy": 0.85,
    "f1_weighted": 0.84,
    "training_time_seconds": 45.3,
    "data_size": 500
  }
}
```

---

### 3. AvaliaÃ§Ã£o do Modelo (GET /evaluate)

Avalia a performance do modelo contra a base de teste (holdout).

#### Usando cURL

```bash
curl -X GET "http://127.0.0.1:8000/evaluate"
```

#### Usando Python

```python
import requests
import json

url = "http://127.0.0.1:8000/evaluate"
response = requests.get(url)
print(json.dumps(response.json(), indent=2, ensure_ascii=False))
```

**Resposta Esperada:**

```json
{
  "accuracy": 0.82,
  "f1_weighted": 0.81,
  "classification_report": {
    "Quartzo": {
      "precision": 0.88,
      "recall": 0.80,
      "f1-score": 0.84
    },
    "Ãgata": {
      "precision": 0.78,
      "recall": 0.75,
      "f1-score": 0.77
    }
  }
}
```

---

### 4. RelatÃ³rio de Data Drift (GET /drift-report)

Gera um relatÃ³rio HTML comparando a distribuiÃ§Ã£o dos dados de treinamento com dados de produÃ§Ã£o.

#### Usando cURL

```bash
curl -X GET "http://127.0.0.1:8000/drift-report" -o drift_report.html
```

#### Usando Python

```python
import requests

url = "http://127.0.0.1:8000/drift-report"
response = requests.get(url)

with open("drift_report.html", "wb") as f:
    f.write(response.content)

print("RelatÃ³rio salvo em: drift_report.html")
```

---

## ğŸ”„ Etapas do Pipeline de Machine Learning

### Diagrama do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dados Brutos (2022-2024)      â”‚
â”‚     diferentes schemas          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. PRÃ‰-PROCESSAMENTO          â”‚
â”‚   â”œâ”€ Carregamento de dados      â”‚
â”‚   â”œâ”€ IdentificaÃ§Ã£o de schema    â”‚
â”‚   â”œâ”€ RenomeaÃ§Ã£o de colunas      â”‚
â”‚   â”œâ”€ Limpeza de tipos           â”‚
â”‚   â””â”€ Tratamento de valores nulosâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. ENGENHARIA DE FEATURES     â”‚
â”‚   â”œâ”€ SeleÃ§Ã£o de features        â”‚
â”‚   â”œâ”€ ImputaÃ§Ã£o (mediana)        â”‚
â”‚   â”œâ”€ CodificaÃ§Ã£o (categorical)  â”‚
â”‚   â””â”€ NormalizaÃ§Ã£o (StandardSca) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. BALANCEAMENTO DE DADOS     â”‚
â”‚   â”œâ”€ DetecÃ§Ã£o de desbalanceio   â”‚
â”‚   â””â”€ SMOTE (oversampling)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   4. DIVISÃƒO DE DADOS           â”‚
â”‚   â”œâ”€ Train: 80%                 â”‚
â”‚   â”œâ”€ Test: 20%                  â”‚
â”‚   â””â”€ ValidaÃ§Ã£o: K-Fold (5)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   5. TREINAMENTO DO MODELO      â”‚
â”‚   â”œâ”€ MLPClassifier (NN)         â”‚
â”‚   â”œâ”€ Hidden layers: (100,)      â”‚
â”‚   â”œâ”€ Max iterations: 2000       â”‚
â”‚   â””â”€ Rastreamento (MLflow)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   6. AVALIAÃ‡ÃƒO DO MODELO        â”‚
â”‚   â”œâ”€ Accuracy                   â”‚
â”‚   â”œâ”€ F1-Score (weighted)        â”‚
â”‚   â”œâ”€ Precision & Recall         â”‚
â”‚   â””â”€ Matriz de ConfusÃ£o         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   7. PERSISTÃŠNCIA               â”‚
â”‚   â”œâ”€ Salvar modelo              â”‚
â”‚   â”œâ”€ Salvar pipeline            â”‚
â”‚   â””â”€ Registrar artefatos        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Modelo em ProduÃ§Ã£o (API)      â”‚
â”‚     PrediÃ§Ãµes em tempo real     â”‚
â”‚     Monitoramento de Drift      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DescriÃ§Ã£o Detalhada das Etapas

#### **1. PrÃ©-Processamento** (`src/preprocessing.py`)

Unifica e limpa dados de mÃºltiplas safras com esquemas heterogÃªneos:

- **IdentificaÃ§Ã£o automÃ¡tica de schema**: Detecta se os dados sÃ£o de 2022, 2023 ou 2024
- **RenomeaÃ§Ã£o de colunas**: Padroniza nomenclatura variÃ¡vel entre anos
- **Limpeza de tipos**:
  - Converte idades incorretas (ex: "1900-01-15" â†’ 15)
  - Normaliza gÃªnero ("Menino" â†’ "Masculino")
  - Corrige ortografia ("Agata" â†’ "Ãgata")
- **Tratamento de valores ausentes**: Flag de detecÃ§Ã£o para imputaÃ§Ã£o posterior

**Exemplos de mapeamento (2022 â†’ 2024):**

```python
{
  "Matem" â†’ "NOTA_MAT",
  "Portug" â†’ "NOTA_PORT",
  "InglÃªs" â†’ "NOTA_ING",
  "Pedra 22" â†’ "PEDRA",
  "Idade 22" â†’ "IDADE"
}
```

#### **2. Engenharia de Features** (`src/feature_engineering.py`)

Transforma dados brutos em features otimizadas para o modelo neural:

- **SeleÃ§Ã£o de features**:
  ```python
  ['IDADE', 'GENERO', 'ANO_INGRESSO', 'FASE', 'DEFASAGEM',
   'NOTA_MAT', 'NOTA_PORT', 'NOTA_ING', 'IEG', 'IPS', 'IAA', 'IPP']
  ```

- **ImputaÃ§Ã£o**: Valores nulos preenchidos com mediana das variÃ¡veis numÃ©ricas
- **CodificaÃ§Ã£o categÃ³rica**: GÃªnero Ã© mapeado para valores numÃ©ricos
- **NormalizaÃ§Ã£o (StandardScaler)**: Centrado em mÃ©dia 0, desvio padrÃ£o 1
  - **FÃ³rmula**: z = (x - Î¼) / Ïƒ

#### **3. Balanceamento de Dados**

Classes desbalanceadas sÃ£o tratadas com **SMOTE** (Synthetic Minority Oversampling):

- Gera amostras sintÃ©ticas para classes minoritÃ¡rias
- MantÃ©m distribuiÃ§Ã£o realÃ­stica dos dados

#### **4. DivisÃ£o de Dados**

- **Train**: 80% dados (para ajuste do modelo)
- **Test**: 20% dados (reserved para avaliaÃ§Ã£o final)
- **ValidaÃ§Ã£o Cruzada**: 5-fold estratificada por grupo (RA do aluno)

#### **5. Treinamento do Modelo** (`src/train.py`)

Treina um **MLPClassifier** (Rede Neural Multicamadas):

```python
MODEL_PARAMS = {
    'hidden_layer_sizes': (100,),  # Uma camada oculta com 100 neurÃ´nios
    'activation': 'relu',          # ReLU como funÃ§Ã£o de ativaÃ§Ã£o
    'alpha': 0.01,                 # RegularizaÃ§Ã£o L2
    'learning_rate_init': 0.001,   # Taxa de aprendizado inicial
    'max_iter': 2000,              # MÃ¡ximo de iteraÃ§Ãµes
    'random_state': 42             # Reprodutibilidade
}
```

- **ValidaÃ§Ã£o Cruzada**: Avalia desempenho em 5 folds
- **Rastreamento MLflow**: Registra mÃ©tricas, parÃ¢metros e artefatos

#### **6. AvaliaÃ§Ã£o do Modelo** (`src/evaluate.py`)

Calcula mÃ©tricas de desempenho no conjunto de teste:

- **Accuracy**: ProporÃ§Ã£o de previsÃµes corretas
- **Precision**: ProporÃ§Ã£o de positivos corretamente identificados
- **Recall**: ProporÃ§Ã£o real de positivos identificados
- **F1-Score**: MÃ©dia harmÃ´nica entre Precision e Recall
- **Matriz de ConfusÃ£o**: VisualizaÃ§Ã£o de erros por classe

#### **7. Monitoramento de Drift** (`src/drift_report.py`)

Detecta mudanÃ§as na distribuiÃ§Ã£o dos dados entre treino e produÃ§Ã£o:

- **Uso da biblioteca Evidently**: Compara distribuiÃ§Ãµes estatÃ­sticas
- **RelatÃ³rio HTML**: VisualizaÃ§Ãµes interativas dos desvios
- **Acionamento automÃ¡tico**: Alertas quando drift Ã© detectado

---

## ğŸ“ Comandos Ãšteis

### Desenvolvimento & Testes

#### Executar Testes Locais

```bash
# Rodar todos os testes
pytest

# Rodar com cobertura de cÃ³digo
pytest --cov=src --cov=app

# Rodar teste especÃ­fico
pytest tests/test_api.py -v

# Rodar teste com output detalhado
pytest -vv -s
```

#### Treinar Modelo Localmente

```bash
# Ativar ambiente virtual (se necessÃ¡rio)
source venv/bin/activate  # No Windows: venv\Scripts\activate

# Executar pipeline de treinamento
python -m src.train
```

#### Avaliar Modelo

```bash
python -m src.evaluate
```

#### Explorar Dados

```bash
# Abrir notebook Jupyter
jupyter notebook notebooks/exploracao_dados.ipynb
```

### Desenvolvimento da API

#### Rodando a API Localmente

```bash
# Ambiente virtual ativado
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Acesse: http://127.0.0.1:8000/docs

#### Acessar MLflow UI

```bash
# Na raiz do projeto
mlflow ui

# Acesse em http://127.0.0.1:5000
```

### Gerenciamento de Docker

```bash
# Verificar containers em execuÃ§Ã£o
docker ps -a

# Ver logs de um container
docker logs -f api-passos-magicos

# Acessar shell do container
docker exec -it api-passos-magicos bash

# Parar um container
docker stop api-passos-magicos

# Remover um container
docker rm api-passos-magicos

# Remover imagem Docker
docker rmi passos-magicos-api:latest

# Limpar recursos nÃ£o utilizados
docker system prune -a
```

### Troubleshooting

#### API nÃ£o inicia apÃ³s container estar rodando

```bash
# Verificar logs
docker-compose logs api-passos-magicos

# Reiniciar serviÃ§o
docker-compose restart api-passos-magicos
```

#### Modelo nÃ£o estÃ¡ carregado

```bash
# Treinar novo modelo via API
curl -X POST "http://127.0.0.1:8000/train"

# Ou via linha de comando
python -m src.train
```

#### Erro de permissÃ£o em volumes Linux

```bash
# Ajustar permissÃµes
sudo chown -R $USER:$USER data/ models/ docs/ mlruns/
```

---

## ğŸ“Š Features e DescriÃ§Ã£o de Entrada

### VariÃ¡veis de Entrada

| VariÃ¡vel | Tipo | DescriÃ§Ã£o | Exemplo |
|----------|------|-----------|---------|
| RA | string | Registro AcadÃªmico (ID Ãºnico do aluno) | "123456" |
| IDADE | float | Idade do aluno em anos | 14.5 |
| GENERO | enum | GÃªnero (Masculino/Feminino/Menino/Menina) | "Menino" |
| ANO_INGRESSO | int | Ano de entrada no programa | 2022 |
| FASE | int | Fase atual do aluno | 1-8 |
| NOTA_MAT | float | Nota em MatemÃ¡tica (0-10) | 8.5 |
| NOTA_PORT | float | Nota em PortuguÃªs (0-10) | 7.0 |
| NOTA_ING | float | Nota em InglÃªs (0-10) | 6.5 |
| IEG | float | Ãndice de Engajamento Global (0-10) | 7.0 |
| IPS | float | Ãndice Psicossocial (0-10) | 6.5 |
| IAA | float | Ãndice de AutoavaliaÃ§Ã£o (0-10) | 8.0 |
| IPP | float | Ãndice PsicopedagÃ³gico (0-10) | 7.5 |
| DEFASAGEM | int | NÃ­vel de defasagem escolar (0, 1, 2...) | 0 |

### VariÃ¡vel Alvo (Output)

| Pedra | ClassificaÃ§Ã£o |
|-------|---------------|
| **Quartzo** | Sem risco aparente |
| **Ãgata** | Risco baixo |
| **Ametista** | Risco mÃ©dio |
| **TopÃ¡zio** | Risco alto |

---

## ğŸ› ï¸ ContribuiÃ§Ãµes e Desenvolvimento

### Adicionar Novas Features

1. Atualizar dados de entrada em `app/schemas.py`
2. Adicionar lÃ³gica de transformaÃ§Ã£o em `src/feature_engineering.py`
3. Atualizar testes em `tests/test_feature_engineering.py`
4. Retreinar modelo via `/train`

### Melhorar o Modelo

1. Ajustar hiperparÃ¢metros em `src/config.py`
2. Testar diferentes algoritmos em um notebook
3. Registrar experimentos no MLflow
4. Comparar mÃ©tricas e selecionar o melhor

---

## ğŸ“ Suporte e DocumentaÃ§Ã£o

- **Swagger UI**: http://127.0.0.1:8000/docs
- **ReDoc**: http://127.0.0.1:8000/redoc
- **MLflow Experiments**: http://127.0.0.1:5000 (apÃ³s `mlflow ui`)

---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para o programa **Passos MÃ¡gicos**.

---

**Ãšltima atualizaÃ§Ã£o**: 13 de fevereiro de 2026
